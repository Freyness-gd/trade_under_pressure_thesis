{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preparation",
   "id": "e8067785cd8d7919"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import modules",
   "id": "1fe72819da94dd5d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:35.635498Z",
     "start_time": "2025-05-22T13:24:35.632758Z"
    }
   },
   "source": [
    "import copy\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "import thesis_utils.datastruc as tuds\n",
    "import thesis_utils.models as tumod"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "4284e3ddbaa79d6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:35.676292Z",
     "start_time": "2025-05-22T13:24:35.672094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Config for saving outputs\n",
    "SAVE_ENABLED = True\n",
    "SERIAL_NUMBER = \"NOT_SET\"\n",
    "\n",
    "# Model parameters\n",
    "SEQ_LEN = 5\n",
    "HORIZON = 1\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 20\n",
    "HIDDEN_SIZE = 128\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# Train parameters\n",
    "TARGET = \"gravity_trade\"\n",
    "FEATURES = [\n",
    "  \"GDP_reporter\",\n",
    "  \"GDP_partner\",\n",
    "  \"distw\",\n",
    "  \"TOTAL\",\n",
    "  \"arms\", \"military\", \"trade\", \"financial\", \"travel\", \"other\",  # sanctions categorical\n",
    "  \"contig\", \"comlang_off\", \"colony\", \"smctry\",  # dist cepii categorical\n",
    "  \"fyear\", \"GDP_yearly_average\"  # additional features\n",
    "]\n",
    "N_SPLITS = 3\n",
    "PATIENCE = 15\n",
    "LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY = 0.01\n",
    "RANDOM_SEED = 16\n",
    "KEEP_FRAC = 1\n",
    "\n",
    "# Torch config\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = (\n",
    "  torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "  else torch.device(\"cpu\")\n",
    ")"
   ],
   "id": "56e9b02ef240fd0a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data",
   "id": "c9e963c3ab4f2220"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:36.063354Z",
     "start_time": "2025-05-22T13:24:35.680101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processed = pa.read_parquet(path=\"../data/model/processed.parquet\", engine=\"fastparquet\")\n",
    "df: DataFrame = processed.copy(deep=True)"
   ],
   "id": "9451e98a113f268d",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sort, shift and compute data",
   "id": "84523341884506e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:36.364286Z",
     "start_time": "2025-05-22T13:24:36.078011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sort data by Report + Partner + Year\n",
    "df[\"dyad_id\"] = df[\"ISO3_reporter\"] + \"_\" + df[\"ISO3_partner\"]\n",
    "df = df.sort_values(by=[\"dyad_id\", \"Year\"], ignore_index=True)"
   ],
   "id": "1dcefe0333d9c64b",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:36.402905Z",
     "start_time": "2025-05-22T13:24:36.390933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add gravity_trade as value column\n",
    "df[\"gravity_trade\"] = np.log1p((df[\"GDP_reporter\"] * df[\"GDP_partner\"]) / df[\"distw\"])\n",
    "df[\"TOTAL\"] = df[\"IMPORT\"] + df[\"EXPORT\"]\n",
    "\n",
    "# Add year feature\n",
    "df[\"fyear\"] = df[\"Year\"]"
   ],
   "id": "80779ed2ae23e3de",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Normalize",
   "id": "d5984693829da5ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:36.609539Z",
     "start_time": "2025-05-22T13:24:36.405801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scale data\n",
    "scale_columns_minmax = [\"GDP_reporter\", \"GDP_partner\", \"TOTAL\", \"fyear\", \"GDP_yearly_average\"]\n",
    "scaler_rb = RobustScaler()\n",
    "scaler_mm = MinMaxScaler()\n",
    "df_scaled: DataFrame = df.copy(deep=True)\n",
    "df_scaled[scale_columns_minmax] = scaler_mm.fit_transform(df[scale_columns_minmax])\n",
    "df_scaled[[\"distw\"]] = scaler_rb.fit_transform(df[[\"distw\"]])"
   ],
   "id": "77dd6217a0e1c4a0",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split data",
   "id": "eab345a3bd4fc194"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:36.658006Z",
     "start_time": "2025-05-22T13:24:36.623678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split into Train, Validation and Test sets\n",
    "idx = np.arange(len(df_scaled))\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "  idx, test_size=0.20, random_state=RANDOM_SEED\n",
    ")\n",
    "train_idx, val_idx = train_test_split(\n",
    "  train_idx, test_size=20, random_state=RANDOM_SEED\n",
    ")"
   ],
   "id": "51433a3f014528c2",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train",
   "id": "1053e63e8a6ccb76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define Fold and Epoch steps\n",
    "_For reusability_"
   ],
   "id": "78e3575a51038c9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:36.673432Z",
     "start_time": "2025-05-22T13:24:36.671496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create KFold object\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)"
   ],
   "id": "8eb0c16ea3f9a15d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:36.689286Z",
     "start_time": "2025-05-22T13:24:36.686290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define epoch step\n",
    "def epoch_step(model: nn.Module, optimizer: Optimizer, criterion: nn.Module,\n",
    "               scheduler: LRScheduler, train_loader: DataLoader, val_loader: DataLoader,\n",
    "               device: any) -> float:\n",
    "  model.train()\n",
    "  for X, y, _ in train_loader:\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(model(X), y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  model.eval()\n",
    "  val_losses = []\n",
    "  with (torch.no_grad()):\n",
    "    for X, y, _ in val_loader:\n",
    "      X = X.to(device)\n",
    "      y = y.to(device)\n",
    "      val_losses.append(criterion(model(X), y).item())\n",
    "\n",
    "  val_rmse = math.sqrt((sum(val_losses) / len(val_losses)))\n",
    "  scheduler.step(val_rmse)\n",
    "  return val_rmse"
   ],
   "id": "82612d122ae0a3ae",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:36.706101Z",
     "start_time": "2025-05-22T13:24:36.702103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define fold step\n",
    "def fold_step(fold: int, train_idx: List, val_idx: List,\n",
    "              dataset: Dataset, batch_size: int, num_epochs: int, patience: int,\n",
    "              model: nn.Module, device: any,\n",
    "              optimizer: Optimizer, criterion: nn.Module, scheduler: LRScheduler) -> (float, dict):\n",
    "  train_loader = DataLoader(\n",
    "    Subset(dataset, train_idx),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    "  )\n",
    "\n",
    "  val_loader = DataLoader(\n",
    "    Subset(dataset, val_idx),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    "  )\n",
    "\n",
    "  best_state = copy.deepcopy(model.state_dict())\n",
    "  best_rmse = float(\"inf\")\n",
    "  patience_left = patience\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    val_rmse = epoch_step(model=model, optimizer=optimizer, criterion=criterion,\n",
    "                          scheduler=scheduler, train_loader=train_loader, val_loader=val_loader,\n",
    "                          device=device)\n",
    "    print(f\"Epoch {epoch + 1:02d}/{num_epochs}  |  val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "    if val_rmse < best_rmse - 1e-4:\n",
    "      best_rmse, patience_left = val_rmse, 10\n",
    "      best_state = model.state_dict()\n",
    "    else:\n",
    "      patience_left -= 1\n",
    "      if patience_left == 0:\n",
    "        print(\"Early stop.\")\n",
    "        break\n",
    "  model.load_state_dict(best_state)\n",
    "  model.eval()\n",
    "  preds, truth = [], []\n",
    "  with torch.no_grad():\n",
    "    for X, y, _ in val_loader:\n",
    "      X = X.to(device)\n",
    "      preds.append(model(X).cpu())\n",
    "      truth.append(y)\n",
    "  preds = torch.cat(preds).numpy()\n",
    "  truth = torch.cat(truth).numpy()\n",
    "\n",
    "  rmse = np.sqrt(((preds - truth) ** 2).mean())\n",
    "  mae = np.abs(preds - truth).mean()\n",
    "  r2 = 1 - ((preds - truth) ** 2).sum() / ((truth - truth.mean()) ** 2).sum()\n",
    "  print(f\" Fold {fold}  RMSE {rmse:.4f} | MAE {mae:.4f} | RÂ² {r2:.4f}\")\n",
    "\n",
    "  return rmse, copy.deepcopy(best_state)\n"
   ],
   "id": "959f98487abc0673",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Raw dataset",
   "id": "13f3e7e01662654"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split dataset",
   "id": "ff153528228b1350"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:36.946177Z",
     "start_time": "2025-05-22T13:24:36.719700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert df_scaled to pytorch Tensor\n",
    "dataset, _ = tuds.make_panel_datasets(data=df_scaled, features=FEATURES, target=TARGET, horizon=HORIZON,\n",
    "                                      keep_frac=KEEP_FRAC)"
   ],
   "id": "e38f7e2869374fc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape original data:  (1099125, 32)\n",
      "Shape sampled:  (1099125, 32)\n",
      "Shape remainder:  (0, 32)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:36.962031Z",
     "start_time": "2025-05-22T13:24:36.959535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create DataLoaders for the 3 sets\n",
    "train_loader = DataLoader(\n",
    "  Subset(dataset, train_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "  Subset(dataset, val_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "  Subset(dataset, test_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False\n",
    ")"
   ],
   "id": "14dd8fdd80d8f0aa",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train model",
   "id": "d9e348e74bd91747"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:36.977052Z",
     "start_time": "2025-05-22T13:24:36.975127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save config\n",
    "SAVE_ENABLED = False\n",
    "SERIAL_NUMBER = f\"BasicLSTM-RawData\""
   ],
   "id": "1b837c71b6de51c1",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:36.991460Z",
     "start_time": "2025-05-22T13:24:36.989682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save best train iteration\n",
    "best_fold_state = None\n",
    "best_fold_rmse = float(\"inf\")"
   ],
   "id": "5e6e1bf43de12079",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-22T13:24:37.005349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(dataset))), 1):\n",
    "  model = tumod.BasicGRU(\n",
    "    n_features=len(FEATURES),\n",
    "    n_layers=N_LAYERS,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    dropout=DROPOUT,\n",
    "    horizon=HORIZON).to(device=device)\n",
    "\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=PATIENCE\n",
    "  )\n",
    "\n",
    "  print(f\"=== FOLD {fold}/{N_SPLITS} ===\")\n",
    "  fold_rmse, best_state = fold_step(fold=fold,\n",
    "                                    train_idx=train_idx,\n",
    "                                    val_idx=val_idx,\n",
    "                                    dataset=dataset,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    num_epochs=NUM_EPOCHS,\n",
    "                                    patience=PATIENCE,\n",
    "                                    model=model,\n",
    "                                    device=device,\n",
    "                                    optimizer=optimizer,\n",
    "                                    criterion=criterion,\n",
    "                                    scheduler=scheduler)\n",
    "  if fold_rmse < best_fold_rmse:\n",
    "    best_fold_rmse = fold_rmse\n",
    "    best_fold_state = copy.deepcopy(best_state)"
   ],
   "id": "46a31ee0542aa6ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FOLD 1/3 ===\n",
      "Epoch 01/20  |  val RMSE: 1.8568\n",
      "Epoch 02/20  |  val RMSE: 1.7172\n",
      "Epoch 03/20  |  val RMSE: 1.7307\n",
      "Epoch 04/20  |  val RMSE: 1.5907\n",
      "Epoch 05/20  |  val RMSE: 1.5882\n",
      "Epoch 06/20  |  val RMSE: 1.3018\n",
      "Epoch 07/20  |  val RMSE: 1.1094\n",
      "Epoch 08/20  |  val RMSE: 1.1029\n",
      "Epoch 09/20  |  val RMSE: 1.0905\n",
      "Epoch 10/20  |  val RMSE: 1.1655\n",
      "Epoch 11/20  |  val RMSE: 0.9776\n",
      "Epoch 12/20  |  val RMSE: 1.0695\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lagged features",
   "id": "16acca6c1bd49c45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split dataset and lag features",
   "id": "9a80e8e906b1ccaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:30.023916Z",
     "start_time": "2025-05-22T12:51:24.757068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert df_scaled to pytorch Tensor\n",
    "LAGGED_COLS = [\"GDP_partner\", \"GDP_reporter\", \"TOTAL\"]\n",
    "LAG = 3\n",
    "dataset, _ = tuds.make_panel_laggedsets(data=df_scaled, features=FEATURES, target=TARGET,\n",
    "                                        lag=LAG, lag_columns=LAGGED_COLS, keep_frac=KEEP_FRAC)"
   ],
   "id": "b5ab62978237f26e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape original data:  (1099125, 32)\n",
      "Shape sampled:  (1099125, 32)\n",
      "Shape remainder:  (0, 32)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:30.027198Z",
     "start_time": "2025-05-22T12:51:25.700555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create DataLoaders for the 3 sets\n",
    "train_loader = DataLoader(\n",
    "  Subset(dataset, train_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=True,\n",
    "  num_workers=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "  Subset(dataset, val_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False,\n",
    "  num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "  Subset(dataset, test_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False,\n",
    "  num_workers=4\n",
    ")"
   ],
   "id": "887f1be35155633c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train model",
   "id": "380a10bb22163818"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:30.040217Z",
     "start_time": "2025-05-22T12:51:25.717846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save config\n",
    "SAVE_ENABLED = False\n",
    "SERIAL_NUMBER = f\"BasicLSTM-LaggedFeatures5\""
   ],
   "id": "583f768f40ee7362",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:30.040978Z",
     "start_time": "2025-05-22T12:51:25.732893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save best train iteration\n",
    "best_fold_state = None\n",
    "best_fold_rmse = float(\"inf\")"
   ],
   "id": "5f8c19f77b7a9182",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:30.041402Z",
     "start_time": "2025-05-22T12:51:25.747806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add lagged feature names\n",
    "LAGGED_FEATURES = copy.deepcopy(FEATURES)\n",
    "for feature in LAGGED_COLS:\n",
    "  for i in range(1, LAG + 1):\n",
    "    LAGGED_FEATURES.append(f\"{feature}_lag{i}\")"
   ],
   "id": "a91e7a56ee9506c3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-05-22T13:24:30.041575Z",
     "start_time": "2025-05-22T12:51:25.762566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(dataset))), 1):\n",
    "  print(f\"=== FOLD {fold}/{N_SPLITS} ===\")\n",
    "  model = tumod.BasicGRU(\n",
    "    n_features=len(LAGGED_FEATURES),\n",
    "    n_layers=N_LAYERS,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    dropout=DROPOUT,\n",
    "    horizon=HORIZON).to(device=device)\n",
    "\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=PATIENCE\n",
    "  )\n",
    "\n",
    "  fold_rmse, best_state = fold_step(fold=fold,\n",
    "                                    train_idx=train_idx,\n",
    "                                    val_idx=val_idx,\n",
    "                                    dataset=dataset,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    num_epochs=NUM_EPOCHS,\n",
    "                                    patience=PATIENCE,\n",
    "                                    model=model,\n",
    "                                    device=device,\n",
    "                                    optimizer=optimizer,\n",
    "                                    criterion=criterion,\n",
    "                                    scheduler=scheduler)\n",
    "  if fold_rmse < best_fold_rmse:\n",
    "    best_fold_rmse = fold_rmse\n",
    "    best_fold_state = copy.deepcopy(best_state)"
   ],
   "id": "2fe1bf848936771e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FOLD 1/3 ===\n",
      "Epoch 01/20  |  val RMSE: 1.5268\n",
      "Epoch 02/20  |  val RMSE: 1.3515\n",
      "Epoch 03/20  |  val RMSE: 1.1812\n",
      "Epoch 04/20  |  val RMSE: 1.0388\n",
      "Epoch 05/20  |  val RMSE: 0.6907\n",
      "Epoch 06/20  |  val RMSE: 0.5752\n",
      "Epoch 07/20  |  val RMSE: 0.9570\n",
      "Epoch 08/20  |  val RMSE: 0.6555\n",
      "Epoch 09/20  |  val RMSE: 0.5155\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Sliding Window",
   "id": "a454996e2bb4107d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert df_scaled to pytorch Tensor\n",
    "dataset, _ = tuds.make_panel_slidingwindows(data=df_scaled, features=FEATURES, target=TARGET, seq_len=SEQ_LEN,\n",
    "                                            horizon=HORIZON, keep_frac=KEEP_FRAC)"
   ],
   "id": "a84b14a7630b603b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split dataset",
   "id": "61810f0acbbd3e15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create DataLoaders for the 3 sets\n",
    "train_loader = DataLoader(\n",
    "  Subset(dataset, train_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=True,\n",
    "  num_workers=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "  Subset(dataset, val_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False,\n",
    "  num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "  Subset(dataset, test_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False,\n",
    "  num_workers=4\n",
    ")"
   ],
   "id": "f35e409ceff91d7c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train model",
   "id": "1243ecaa8b4c36f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save config\n",
    "SAVE_ENABLED = False\n",
    "SERIAL_NUMBER = f\"BasicLSTM-SlidingWindow{SEQ_LEN}\""
   ],
   "id": "f2aa8e2108619f0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save best train iteration\n",
    "best_fold_state = None\n",
    "best_fold_rmse = float(\"inf\")"
   ],
   "id": "598262d9e53b33e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(dataset))), 1):\n",
    "  print(f\"=== FOLD {fold}/{N_SPLITS} ===\")\n",
    "  model = tumod.BasicGRU(\n",
    "    n_features=len(FEATURES),\n",
    "    n_layers=N_LAYERS,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    dropout=DROPOUT,\n",
    "    horizon=HORIZON).to(device=device)\n",
    "\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=PATIENCE\n",
    "  )\n",
    "\n",
    "  fold_rmse, best_state = fold_step(fold=fold,\n",
    "                                    train_idx=train_idx,\n",
    "                                    val_idx=val_idx,\n",
    "                                    dataset=dataset,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    num_epochs=NUM_EPOCHS,\n",
    "                                    patience=PATIENCE,\n",
    "                                    model=model,\n",
    "                                    device=device,\n",
    "                                    optimizer=optimizer,\n",
    "                                    criterion=criterion,\n",
    "                                    scheduler=scheduler)\n",
    "  if fold_rmse < best_fold_rmse:\n",
    "    best_fold_rmse = fold_rmse\n",
    "    best_fold_state = copy.deepcopy(best_state)"
   ],
   "id": "7c7e8f1fa54e92a1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
