{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8067785cd8d7919",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe72819da94dd5d",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "id": "49f2c526a22d4a8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:31.033679Z",
     "start_time": "2025-06-29T20:31:30.846850Z"
    }
   },
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport thesis_utils"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:31.706196Z",
     "start_time": "2025-06-29T20:31:31.036977Z"
    }
   },
   "source": [
    "import copy\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "import thesis_utils as tu\n",
    "import thesis_utils.datastruc as tuds\n",
    "import thesis_utils.models as tumod"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "4284e3ddbaa79d6f",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:31.768566Z",
     "start_time": "2025-06-29T20:31:31.752069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model parameters\n",
    "HORIZON = 1\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 25\n",
    "HIDDEN_SIZE = 128\n",
    "N_LAYERS = 3\n",
    "DROPOUT = 0.2\n",
    "EMBEDDING_SIZE = 32\n",
    "\n",
    "# Train parameters\n",
    "TARGET = \"EXPORT_centered\"\n",
    "FEATURES = [\n",
    "  \"contig\", \"comlang_off\", \"colony\", \"smctry\",\n",
    "]\n",
    "N_SPLITS = 5\n",
    "PATIENCE = 5\n",
    "LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY = 0.01\n",
    "RANDOM_SEED = 16\n",
    "N_LAGS = 5\n",
    "SUBSAMPLE_ENABLED = False\n",
    "N_DYADS = 1000\n",
    "\n",
    "SANCTION_COLS = [\"arms\", \"military\", \"trade\", \"travel\", \"other\"]\n",
    "\n",
    "# Torch config\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = (\n",
    "  torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "  else torch.device(\"cpu\")\n",
    ")"
   ],
   "id": "61e300229ad638a6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "c9e963c3ab4f2220",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "9451e98a113f268d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:32.070416Z",
     "start_time": "2025-06-29T20:31:31.772454Z"
    }
   },
   "source": [
    "processed = pd.read_parquet(path=\"../../data/model/processed.parquet\", engine=\"fastparquet\")\n",
    "df: DataFrame = processed.copy(deep=True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "84523341884506e1",
   "metadata": {},
   "source": [
    "### Sort, shift and compute data"
   ]
  },
  {
   "cell_type": "code",
   "id": "1dcefe0333d9c64b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:32.330145Z",
     "start_time": "2025-06-29T20:31:32.080444Z"
    }
   },
   "source": [
    "# Sort data by Report + Partner + Year\n",
    "df[\"dyad_id\"] = df[\"ISO3_reporter\"] + \"_\" + df[\"ISO3_partner\"]\n",
    "df = df.sort_values(by=[\"dyad_id\", \"Year\"], ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "80b184ad01b2ba40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:32.363464Z",
     "start_time": "2025-06-29T20:31:32.338889Z"
    }
   },
   "source": [
    "if SUBSAMPLE_ENABLED:\n",
    "  dyad_subsample = pd.Series(df[\"dyad_id\"].unique()).sample(n=N_DYADS, random_state=RANDOM_SEED, replace=False)\n",
    "  df = df[df[\"dyad_id\"].isin(dyad_subsample)]\n",
    "print(df[\"dyad_id\"].nunique())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33672\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "a85175edfb33ec5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:32.428809Z",
     "start_time": "2025-06-29T20:31:32.371247Z"
    }
   },
   "source": [
    "df[\"sanction\"] = (df[SANCTION_COLS]\n",
    "                  .sum(axis=1)).astype(int)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "fc95e2c1d62df96f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:32.609004Z",
     "start_time": "2025-06-29T20:31:32.435837Z"
    }
   },
   "source": [
    "num_cols = [\"distw\", \"GDP_reporter\", \"GDP_partner\", \"sanction\", \"contig\",\n",
    "            \"comlang_off\", \"colony\", \"smctry\", \"Year\", ]\n",
    "df[num_cols] = df[num_cols].apply(pd.to_numeric, errors=\"coerce\").astype(float)\n",
    "df = df.dropna(subset=num_cols)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "edde8db3cf1500e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:32.675538Z",
     "start_time": "2025-06-29T20:31:32.616859Z"
    }
   },
   "source": [
    "df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "for col in [\"dyad_id\"]:\n",
    "  df[col] = pd.Categorical(df[col], categories=sorted(df[col].unique()))"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "108e39049eaf7466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:32.724776Z",
     "start_time": "2025-06-29T20:31:32.682736Z"
    }
   },
   "source": [
    "center_columns = [\"distw\", \"GDP_reporter\", \"GDP_partner\", \"EXPORT\"]\n",
    "for col in center_columns:\n",
    "  col_max = df[col].max()\n",
    "  col_min = df[col].min()\n",
    "  median = df[col].median()\n",
    "  std_df = df[col].std()\n",
    "  df[col + \"_centered\"] = (df[col] - median) / std_df\n",
    "FEATURES += [\"distw_centered\"]"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:32.962822Z",
     "start_time": "2025-06-29T20:31:32.734116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lag_cols = [\"GDP_reporter_centered\", \"GDP_partner_centered\", \"sanction\"]\n",
    "for col in lag_cols:\n",
    "  for index in range(1, N_LAGS + 1):\n",
    "    df[f\"{col}_lag{index}\"] = df.groupby(\"dyad_id\", observed=True)[col].shift(index)"
   ],
   "id": "5c0f1c2007413797",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:33.198707Z",
     "start_time": "2025-06-29T20:31:32.970308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.dropna()\n",
    "FEATURES += [f\"{c}_lag{index}\" for c in lag_cols for index in range(1, N_LAGS + 1)]"
   ],
   "id": "acf061daf2e88970",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:33.226339Z",
     "start_time": "2025-06-29T20:31:33.207033Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"EXPORT_centered\"].describe()",
   "id": "88815813aaf06b5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.010187e+06\n",
       "mean     7.904368e-02\n",
       "std      1.075389e+00\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      0.000000e+00\n",
       "75%      1.100170e-03\n",
       "max      1.382330e+02\n",
       "Name: EXPORT_centered, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "4c7b73ff292ce4b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:33.250149Z",
     "start_time": "2025-06-29T20:31:33.248350Z"
    }
   },
   "source": [
    "# df_corr_input = df[FEATURES + [TARGET]].copy()\n",
    "# df_corr_input = df_corr_input.apply(pd.to_numeric, errors=\"coerce\")\n",
    "# corr = df_corr_input.corr(method=\"pearson\")\n",
    "#\n",
    "# # --- 4. Plot heat-map -------------------------------------------------------\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# # Show only one triangle to avoid duplicate information\n",
    "# mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "#\n",
    "# sns.heatmap(\n",
    "#   corr,\n",
    "#   mask=mask,\n",
    "#   annot=True,  # write the coefficients\n",
    "#   fmt=\".2f\",\n",
    "#   cmap=\"coolwarm\",  # diverging blue–red palette\n",
    "#   vmin=-1, vmax=1,\n",
    "#   linewidths=0.5,\n",
    "#   cbar_kws={ \"shrink\": 0.8, \"label\": \"Pearson r\" }\n",
    "# )\n",
    "#\n",
    "# plt.title(\"Pearson Correlation Matrix: Features & Target\", pad=20, fontsize=14)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "eab345a3bd4fc194",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "id": "24d7d66b2ad00570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:33.292967Z",
     "start_time": "2025-06-29T20:31:33.272354Z"
    }
   },
   "source": [
    "# Embeddings\n",
    "dyad_to_idx = { dyad: i for i, dyad in enumerate(df[\"dyad_id\"].cat.categories) }\n",
    "df[\"dyad_idx\"] = df[\"dyad_id\"].map(dyad_to_idx).astype(int)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "692abefb91ccfc87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:34.051494Z",
     "start_time": "2025-06-29T20:31:33.319698Z"
    }
   },
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "train_idx, test_idx = next(gss.split(df, groups=df[\"dyad_id\"]))\n",
    "test_df = df.iloc[test_idx]\n",
    "train_df = df.iloc[train_idx]\n",
    "\n",
    "train_idx, val_idx = next(gss.split(train_df, groups=train_df[\"dyad_id\"]))\n",
    "val_df = train_df.iloc[val_idx]\n",
    "train_df = train_df.iloc[train_idx]"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "39f48c81f014cfe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:34.131803Z",
     "start_time": "2025-06-29T20:31:34.092498Z"
    }
   },
   "source": [
    "train_df.loc[:, FEATURES] = train_df.loc[:, FEATURES].astype(\n",
    "  \"float32\",\n",
    "  copy=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "1053e63e8a6ccb76",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e3575a51038c9d",
   "metadata": {},
   "source": [
    "## Define Fold and Epoch steps\n",
    "_For reusability_"
   ]
  },
  {
   "cell_type": "code",
   "id": "8eb0c16ea3f9a15d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:34.150740Z",
     "start_time": "2025-06-29T20:31:34.148728Z"
    }
   },
   "source": [
    "# Create KFold object\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "82612d122ae0a3ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:34.167662Z",
     "start_time": "2025-06-29T20:31:34.165013Z"
    }
   },
   "source": [
    "# Define epoch step\n",
    "def epoch_step(model: nn.Module, optimizer: Optimizer, criterion: nn.Module,\n",
    "               scheduler: LRScheduler, train_loader: DataLoader, val_loader: DataLoader,\n",
    "               device: any) -> float:\n",
    "  model.train()\n",
    "  for X, y, di in train_loader:\n",
    "    X, y, di = map(lambda t: t.to(device, non_blocking=True), (X, y, di))\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(model(X, di), y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  model.eval()\n",
    "  val_losses = []\n",
    "  with (torch.no_grad()):\n",
    "    for X, y, di in val_loader:\n",
    "      X, y, di = map(lambda t: t.to(device, non_blocking=True), (X, y, di))\n",
    "      val_losses.append(criterion(model(X, di), y).item())\n",
    "\n",
    "  val_rmse = math.sqrt((sum(val_losses) / len(val_losses)))\n",
    "  scheduler.step(val_rmse)\n",
    "  return val_rmse"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "959f98487abc0673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:34.185100Z",
     "start_time": "2025-06-29T20:31:34.181301Z"
    }
   },
   "source": [
    "# Define fold step\n",
    "def fold_step(fold: int, train_idx: List, val_idx: List,\n",
    "              dataset: Dataset, batch_size: int, num_epochs: int, patience: int,\n",
    "              model: nn.Module, device: any,\n",
    "              optimizer: Optimizer, criterion: nn.Module, scheduler: LRScheduler) -> (float, dict):\n",
    "  train_loader = DataLoader(\n",
    "    Subset(dataset, train_idx),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory=True\n",
    "  )\n",
    "\n",
    "  val_loader = DataLoader(\n",
    "    Subset(dataset, val_idx),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=10,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory=False\n",
    "  )\n",
    "\n",
    "  best_state = copy.deepcopy(model.state_dict())\n",
    "  best_rmse = float(\"inf\")\n",
    "  patience_left = patience\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    val_rmse = epoch_step(model=model, optimizer=optimizer, criterion=criterion,\n",
    "                          scheduler=scheduler, train_loader=train_loader, val_loader=val_loader,\n",
    "                          device=device)\n",
    "    print(f\"Epoch {epoch + 1:02d}/{num_epochs}  |  val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "    if val_rmse < best_rmse - 1e-4:\n",
    "      best_rmse, patience_left = val_rmse, 10\n",
    "      best_state = model.state_dict()\n",
    "    else:\n",
    "      patience_left -= 1\n",
    "      if patience_left == 0:\n",
    "        print(\"Early stop.\")\n",
    "        break\n",
    "  model.load_state_dict(best_state)\n",
    "  model.eval()\n",
    "  preds, truth = [], []\n",
    "  with torch.no_grad():\n",
    "    for X, y, di in val_loader:\n",
    "      X, di = map(lambda t: t.to(device, non_blocking=True), (X, di))\n",
    "      preds.append(model(X, di).cpu())\n",
    "      truth.append(y)\n",
    "  preds = torch.cat(preds).numpy()\n",
    "  truth = torch.cat(truth).numpy()\n",
    "\n",
    "  rmse = tu.rmse(truth, preds)\n",
    "  mae = tu.mae(truth, preds)\n",
    "  rmae = tu.rmae(truth, preds)\n",
    "  pseudo_r2 = tu.pseudo_r2(truth, preds)\n",
    "  print(f\"Fold {fold}  RMSE {rmse:.4f} | MAE {mae:.4f} | R² {pseudo_r2:.4f} | RMAE {rmae:.4f}\")\n",
    "\n",
    "  return rmse, copy.deepcopy(best_state)\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "13f3e7e01662654",
   "metadata": {},
   "source": [
    "## Raw dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff153528228b1350",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "e38f7e2869374fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:34.404193Z",
     "start_time": "2025-06-29T20:31:34.211141Z"
    }
   },
   "source": [
    "dataset, dyad_to_idx = tuds.make_panel_datasets_dyad(\n",
    "  data=df,\n",
    "  features=FEATURES,\n",
    "  target=TARGET,\n",
    "  horizon=HORIZON,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "14dd8fdd80d8f0aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:34.409582Z",
     "start_time": "2025-06-29T20:31:34.407156Z"
    }
   },
   "source": [
    "# Create DataLoaders for the 3 sets\n",
    "train_loader = DataLoader(\n",
    "  Subset(dataset, train_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=True,\n",
    "  num_workers=10,\n",
    "  persistent_workers=True,\n",
    "  prefetch_factor=2,\n",
    "  pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "  Subset(dataset, val_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False,\n",
    "  num_workers=10,\n",
    "  persistent_workers=True,\n",
    "  prefetch_factor=2,\n",
    "  pin_memory=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "  Subset(dataset, test_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False,\n",
    "  num_workers=10,\n",
    "  persistent_workers=True,\n",
    "  prefetch_factor=2,\n",
    "  pin_memory=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "d9e348e74bd91747",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "id": "1b837c71b6de51c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:34.424380Z",
     "start_time": "2025-06-29T20:31:34.422666Z"
    }
   },
   "source": [
    "# Save config\n",
    "SAVE_ENABLED = False\n",
    "SERIAL_NUMBER = f\"GRU-{LEARNING_RATE}lr-{DROPOUT}d-{HIDDEN_SIZE}hs\"\n",
    "SERIAL_NUMBER = SERIAL_NUMBER.replace(\".\", \"_\")\n",
    "PATH_TO_FOLDER = \"../../models/\""
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "5e6e1bf43de12079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:31:34.438767Z",
     "start_time": "2025-06-29T20:31:34.436946Z"
    }
   },
   "source": [
    "# Save best train iteration\n",
    "best_fold_state = None\n",
    "best_fold_rmse = float(\"inf\")"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "46a31ee0542aa6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T22:10:37.522895Z",
     "start_time": "2025-06-29T20:31:34.467064Z"
    }
   },
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(dataset))), 1):\n",
    "  model = tumod.DyadGRU(\n",
    "    n_features=len(FEATURES),\n",
    "    n_layers=N_LAYERS,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    dropout=DROPOUT,\n",
    "    horizon=HORIZON,\n",
    "    n_dyads=len(dyad_to_idx),\n",
    "    embed_dim=EMBEDDING_SIZE\n",
    "  ).to(device=device)\n",
    "\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=PATIENCE\n",
    "  )\n",
    "\n",
    "  print(f\"=== FOLD {fold}/{N_SPLITS} ===\")\n",
    "  fold_rmse, best_state = fold_step(fold=fold,\n",
    "                                    train_idx=train_idx,\n",
    "                                    val_idx=val_idx,\n",
    "                                    dataset=dataset,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    num_epochs=NUM_EPOCHS,\n",
    "                                    patience=PATIENCE,\n",
    "                                    model=model,\n",
    "                                    device=device,\n",
    "                                    optimizer=optimizer,\n",
    "                                    criterion=criterion,\n",
    "                                    scheduler=scheduler)\n",
    "  if fold_rmse < best_fold_rmse:\n",
    "    best_fold_rmse = fold_rmse\n",
    "    best_fold_state = copy.deepcopy(best_state)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FOLD 1/5 ===\n",
      "Epoch 01/25  |  val RMSE: 0.8719\n",
      "Epoch 02/25  |  val RMSE: 0.9397\n",
      "Epoch 03/25  |  val RMSE: 0.8616\n",
      "Epoch 04/25  |  val RMSE: 0.8191\n",
      "Epoch 05/25  |  val RMSE: 0.7833\n",
      "Epoch 06/25  |  val RMSE: 0.8635\n",
      "Epoch 07/25  |  val RMSE: 0.7524\n",
      "Epoch 08/25  |  val RMSE: 1.0240\n",
      "Epoch 09/25  |  val RMSE: 0.8084\n",
      "Epoch 10/25  |  val RMSE: 0.7987\n",
      "Epoch 11/25  |  val RMSE: 0.7441\n",
      "Epoch 12/25  |  val RMSE: 0.9384\n",
      "Epoch 13/25  |  val RMSE: 0.8702\n",
      "Epoch 14/25  |  val RMSE: 0.8800\n",
      "Epoch 15/25  |  val RMSE: 0.8297\n",
      "Epoch 16/25  |  val RMSE: 0.9630\n",
      "Epoch 17/25  |  val RMSE: 0.8228\n",
      "Epoch 18/25  |  val RMSE: 0.6427\n",
      "Epoch 19/25  |  val RMSE: 0.6256\n",
      "Epoch 20/25  |  val RMSE: 0.7416\n",
      "Epoch 21/25  |  val RMSE: 0.6592\n",
      "Epoch 22/25  |  val RMSE: 0.7405\n",
      "Epoch 23/25  |  val RMSE: 0.6402\n",
      "Epoch 24/25  |  val RMSE: 0.7365\n",
      "Epoch 25/25  |  val RMSE: 0.5928\n",
      "Fold 1  RMSE 0.5929 | MAE 0.0505 | R² 0.7579 | RMAE 0.6034\n",
      "=== FOLD 2/5 ===\n",
      "Epoch 01/25  |  val RMSE: 0.7093\n",
      "Epoch 02/25  |  val RMSE: 0.6789\n",
      "Epoch 03/25  |  val RMSE: 0.6746\n",
      "Epoch 04/25  |  val RMSE: 0.7344\n",
      "Epoch 05/25  |  val RMSE: 0.7079\n",
      "Epoch 06/25  |  val RMSE: 0.7294\n",
      "Epoch 07/25  |  val RMSE: 0.6428\n",
      "Epoch 08/25  |  val RMSE: 0.6926\n",
      "Epoch 09/25  |  val RMSE: 0.6371\n",
      "Epoch 10/25  |  val RMSE: 0.7142\n",
      "Epoch 11/25  |  val RMSE: 0.6997\n",
      "Epoch 12/25  |  val RMSE: 0.6522\n",
      "Epoch 13/25  |  val RMSE: 0.6465\n",
      "Epoch 14/25  |  val RMSE: 0.7021\n",
      "Epoch 15/25  |  val RMSE: 0.6404\n",
      "Epoch 16/25  |  val RMSE: 0.5431\n",
      "Epoch 17/25  |  val RMSE: 0.6060\n",
      "Epoch 18/25  |  val RMSE: 0.6193\n",
      "Epoch 19/25  |  val RMSE: 0.6164\n",
      "Epoch 20/25  |  val RMSE: 0.5108\n",
      "Epoch 21/25  |  val RMSE: 0.5033\n",
      "Epoch 22/25  |  val RMSE: 0.5690\n",
      "Epoch 23/25  |  val RMSE: 0.4777\n",
      "Epoch 24/25  |  val RMSE: 0.5997\n",
      "Epoch 25/25  |  val RMSE: 0.5710\n",
      "Fold 2  RMSE 0.5711 | MAE 0.0562 | R² 0.7086 | RMAE 0.7118\n",
      "=== FOLD 3/5 ===\n",
      "Epoch 01/25  |  val RMSE: 0.6413\n",
      "Epoch 02/25  |  val RMSE: 0.6969\n",
      "Epoch 03/25  |  val RMSE: 0.5796\n",
      "Epoch 04/25  |  val RMSE: 0.5772\n",
      "Epoch 05/25  |  val RMSE: 0.5958\n",
      "Epoch 06/25  |  val RMSE: 0.6118\n",
      "Epoch 07/25  |  val RMSE: 0.6576\n",
      "Epoch 08/25  |  val RMSE: 0.6335\n",
      "Epoch 09/25  |  val RMSE: 0.6291\n",
      "Epoch 10/25  |  val RMSE: 0.6266\n",
      "Epoch 11/25  |  val RMSE: 0.4795\n",
      "Epoch 12/25  |  val RMSE: 0.4679\n",
      "Epoch 13/25  |  val RMSE: 0.5295\n",
      "Epoch 14/25  |  val RMSE: 0.4622\n",
      "Epoch 15/25  |  val RMSE: 0.4408\n",
      "Epoch 16/25  |  val RMSE: 0.4632\n",
      "Epoch 17/25  |  val RMSE: 0.4406\n",
      "Epoch 18/25  |  val RMSE: 0.4703\n",
      "Epoch 19/25  |  val RMSE: 0.4191\n",
      "Epoch 20/25  |  val RMSE: 0.4417\n",
      "Epoch 21/25  |  val RMSE: 0.5495\n",
      "Epoch 22/25  |  val RMSE: 0.4333\n",
      "Epoch 23/25  |  val RMSE: 0.4126\n",
      "Epoch 24/25  |  val RMSE: 0.4021\n",
      "Epoch 25/25  |  val RMSE: 0.4131\n",
      "Fold 3  RMSE 0.4132 | MAE 0.0501 | R² 0.8060 | RMAE 0.6789\n",
      "=== FOLD 4/5 ===\n",
      "Epoch 01/25  |  val RMSE: 0.8977\n",
      "Epoch 02/25  |  val RMSE: 0.8143\n",
      "Epoch 03/25  |  val RMSE: 0.8267\n",
      "Epoch 04/25  |  val RMSE: 0.6789\n",
      "Epoch 05/25  |  val RMSE: 0.8835\n",
      "Epoch 06/25  |  val RMSE: 0.6604\n",
      "Epoch 07/25  |  val RMSE: 0.7940\n",
      "Epoch 08/25  |  val RMSE: 0.7978\n",
      "Epoch 09/25  |  val RMSE: 0.6988\n",
      "Epoch 10/25  |  val RMSE: 0.7711\n",
      "Epoch 11/25  |  val RMSE: 0.8583\n",
      "Epoch 12/25  |  val RMSE: 0.6338\n",
      "Epoch 13/25  |  val RMSE: 0.7745\n",
      "Epoch 14/25  |  val RMSE: 0.7665\n",
      "Epoch 15/25  |  val RMSE: 0.7990\n",
      "Epoch 16/25  |  val RMSE: 0.7415\n",
      "Epoch 17/25  |  val RMSE: 0.7111\n",
      "Epoch 18/25  |  val RMSE: 0.6363\n",
      "Epoch 19/25  |  val RMSE: 0.5717\n",
      "Epoch 20/25  |  val RMSE: 0.5896\n",
      "Epoch 21/25  |  val RMSE: 0.6299\n",
      "Epoch 22/25  |  val RMSE: 0.6211\n",
      "Epoch 23/25  |  val RMSE: 0.6611\n",
      "Epoch 24/25  |  val RMSE: 0.4814\n",
      "Epoch 25/25  |  val RMSE: 0.5343\n",
      "Fold 4  RMSE 0.5344 | MAE 0.0940 | R² 0.7664 | RMAE 1.1728\n",
      "=== FOLD 5/5 ===\n",
      "Epoch 01/25  |  val RMSE: 0.7073\n",
      "Epoch 02/25  |  val RMSE: 0.8279\n",
      "Epoch 03/25  |  val RMSE: 0.7250\n",
      "Epoch 04/25  |  val RMSE: 0.7675\n",
      "Epoch 05/25  |  val RMSE: 0.6410\n",
      "Epoch 06/25  |  val RMSE: 0.7770\n",
      "Epoch 07/25  |  val RMSE: 0.6872\n",
      "Epoch 08/25  |  val RMSE: 0.6758\n",
      "Epoch 09/25  |  val RMSE: 0.6169\n",
      "Epoch 10/25  |  val RMSE: 0.6812\n",
      "Epoch 11/25  |  val RMSE: 0.7274\n",
      "Epoch 12/25  |  val RMSE: 0.5987\n",
      "Epoch 13/25  |  val RMSE: 0.6050\n",
      "Epoch 14/25  |  val RMSE: 0.7584\n",
      "Epoch 15/25  |  val RMSE: 0.7054\n",
      "Epoch 16/25  |  val RMSE: 0.7113\n",
      "Epoch 17/25  |  val RMSE: 0.6590\n",
      "Epoch 18/25  |  val RMSE: 0.6784\n",
      "Epoch 19/25  |  val RMSE: 0.5695\n",
      "Epoch 20/25  |  val RMSE: 0.5314\n",
      "Epoch 21/25  |  val RMSE: 0.5305\n",
      "Epoch 22/25  |  val RMSE: 0.5226\n",
      "Epoch 23/25  |  val RMSE: 0.4835\n",
      "Epoch 24/25  |  val RMSE: 0.5775\n",
      "Epoch 25/25  |  val RMSE: 0.4290\n",
      "Fold 5  RMSE 0.4290 | MAE 0.0407 | R² 0.8340 | RMAE 0.5189\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save Model",
   "id": "cd40d16b5dfd6b2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T22:10:42.190350Z",
     "start_time": "2025-06-29T22:10:42.164757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save({\n",
    "  \"model_state_dict\": best_fold_state,\n",
    "  \"model_hyperparams\": {\n",
    "    \"n_features\": len(FEATURES),\n",
    "    \"n_dyads\": len(dyad_to_idx),\n",
    "    \"embed_dim\": EMBEDDING_SIZE,\n",
    "    \"hidden_size\": HIDDEN_SIZE,\n",
    "    \"n_layers\": N_LAYERS,\n",
    "    \"dropout\": DROPOUT,\n",
    "    \"horizon\": HORIZON,\n",
    "  },\n",
    "  \"dyad_to_idx\": dyad_to_idx,\n",
    "  \"feature_names\": FEATURES,\n",
    "}, PATH_TO_FOLDER + SERIAL_NUMBER + \".pt\")"
   ],
   "id": "c2a97ceadc0c0d16",
   "outputs": [],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
