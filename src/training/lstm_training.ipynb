{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BasicLSTM",
   "id": "a1d433415f0426aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation",
   "id": "e8067785cd8d7919"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import modules",
   "id": "1fe72819da94dd5d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:22.247089Z",
     "start_time": "2025-06-29T20:33:21.148354Z"
    }
   },
   "source": [
    "# Prediction using LSTM, GRU-LSTM, xLSTM\n",
    "import copy\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import KFold, GroupShuffleSplit\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "import thesis_utils.datastruc as tuds\n",
    "import thesis_utils.models as tumod"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Configuration",
   "id": "4284e3ddbaa79d6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:22.267642Z",
     "start_time": "2025-06-29T20:33:22.250227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model parameters\n",
    "HORIZON = 1\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 25\n",
    "HIDDEN_SIZE = 128\n",
    "N_LAYERS = 3\n",
    "DROPOUT = 0.3\n",
    "EMBEDDING_SIZE = 32\n",
    "\n",
    "# Train parameters\n",
    "TARGET = \"EXPORT_centered\"\n",
    "FEATURES = [\n",
    "  \"contig\", \"comlang_off\", \"colony\", \"smctry\",  # dist cepii categorical\n",
    "]\n",
    "N_SPLITS = 5\n",
    "PATIENCE = 5\n",
    "LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY = 0.01\n",
    "RANDOM_SEED = 16\n",
    "KEEP_FRAC = 1.0\n",
    "N_LAGS = 5\n",
    "SUBSAMPLE_ENABLED = False\n",
    "N_DYADS = 1000\n",
    "\n",
    "SANCTION_COLS = [\"arms\", \"military\", \"trade\", \"travel\", \"other\"]\n",
    "\n",
    "# Torch config\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = (\n",
    "  torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "  else torch.device(\"cpu\")\n",
    ")"
   ],
   "id": "56e9b02ef240fd0a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Data",
   "id": "c9e963c3ab4f2220"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:22.693900Z",
     "start_time": "2025-06-29T20:33:22.326034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processed = pd.read_parquet(path=\"../../data/model/processed.parquet\", engine=\"fastparquet\")\n",
    "df: DataFrame = processed.copy(deep=True)"
   ],
   "id": "9451e98a113f268d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sort, shift and compute data",
   "id": "84523341884506e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:22.988971Z",
     "start_time": "2025-06-29T20:33:22.726347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sort data by Report + Partner + Year\n",
    "df[\"dyad_id\"] = df[\"ISO3_reporter\"] + \"_\" + df[\"ISO3_partner\"]\n",
    "df = df.sort_values(by=[\"dyad_id\", \"Year\"], ignore_index=True)"
   ],
   "id": "1dcefe0333d9c64b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:23.026158Z",
     "start_time": "2025-06-29T20:33:22.997687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if SUBSAMPLE_ENABLED:\n",
    "  dyad_subsample = pd.Series(df[\"dyad_id\"].unique()).sample(n=N_DYADS, random_state=RANDOM_SEED, replace=False)\n",
    "  df = df[df[\"dyad_id\"].isin(dyad_subsample)]\n",
    "print(df[\"dyad_id\"].nunique())"
   ],
   "id": "37ec201db709a960",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33672\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:23.096099Z",
     "start_time": "2025-06-29T20:33:23.034722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[\"sanction\"] = (df[SANCTION_COLS]\n",
    "                  .sum(axis=1)).astype(int)"
   ],
   "id": "3fccd13d0f035fe6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Coerce numerical values and convert dyad_id to categorical",
   "id": "7a9d823465c895"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:23.322828Z",
     "start_time": "2025-06-29T20:33:23.103793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_cols = [\"distw\", \"GDP_reporter\", \"GDP_partner\", \"sanction\", \"contig\",\n",
    "            \"comlang_off\", \"colony\", \"smctry\", \"Year\", ]\n",
    "df[num_cols] = df[num_cols].apply(pd.to_numeric, errors=\"coerce\").astype(float)\n",
    "df = df.dropna(subset=num_cols)"
   ],
   "id": "213988af4aee1df1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:23.399941Z",
     "start_time": "2025-06-29T20:33:23.330896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "for col in [\"dyad_id\"]:\n",
    "  df[col] = pd.Categorical(df[col], categories=sorted(df[col].unique()))"
   ],
   "id": "c56872ce3b8a13d9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Center data",
   "id": "d5984693829da5ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:23.450558Z",
     "start_time": "2025-06-29T20:33:23.407907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "center_columns = [\"distw\", \"GDP_reporter\", \"GDP_partner\", \"EXPORT\"]\n",
    "for col in center_columns:\n",
    "  col_max = df[col].max()\n",
    "  col_min = df[col].min()\n",
    "  median = df[col].median()\n",
    "  std_df = df[col].std()\n",
    "  df[col + \"_centered\"] = (df[col] - median) / std_df\n",
    "\n",
    "FEATURES += [\"distw_centered\"]"
   ],
   "id": "aeb1d300d2098b4f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:23.706121Z",
     "start_time": "2025-06-29T20:33:23.458267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lag_cols = [\"GDP_reporter_centered\", \"GDP_partner_centered\", \"sanction\"]\n",
    "for col in lag_cols:\n",
    "  for index in range(1, N_LAGS + 1):\n",
    "    df[f\"{col}_lag{index}\"] = df.groupby(\"dyad_id\", observed=True)[col].shift(index)"
   ],
   "id": "453b168d67f61597",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:23.970902Z",
     "start_time": "2025-06-29T20:33:23.714104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.dropna()\n",
    "FEATURES += [f\"{c}_lag{index}\" for c in lag_cols for index in range(1, N_LAGS + 1)]"
   ],
   "id": "b8a11cdcaed5f54b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:23.982871Z",
     "start_time": "2025-06-29T20:33:23.979724Z"
    }
   },
   "cell_type": "code",
   "source": "FEATURES",
   "id": "ae986f5126d8781d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contig',\n",
       " 'comlang_off',\n",
       " 'colony',\n",
       " 'smctry',\n",
       " 'distw_centered',\n",
       " 'GDP_reporter_centered_lag1',\n",
       " 'GDP_reporter_centered_lag2',\n",
       " 'GDP_reporter_centered_lag3',\n",
       " 'GDP_reporter_centered_lag4',\n",
       " 'GDP_reporter_centered_lag5',\n",
       " 'GDP_partner_centered_lag1',\n",
       " 'GDP_partner_centered_lag2',\n",
       " 'GDP_partner_centered_lag3',\n",
       " 'GDP_partner_centered_lag4',\n",
       " 'GDP_partner_centered_lag5',\n",
       " 'sanction_lag1',\n",
       " 'sanction_lag2',\n",
       " 'sanction_lag3',\n",
       " 'sanction_lag4',\n",
       " 'sanction_lag5']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split data",
   "id": "eab345a3bd4fc194"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:24.012745Z",
     "start_time": "2025-06-29T20:33:23.991233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embeddings\n",
    "dyad_to_idx = { dyad: i for i, dyad in enumerate(df[\"dyad_id\"].cat.categories) }\n",
    "df[\"dyad_idx\"] = df[\"dyad_id\"].map(dyad_to_idx).astype(int)"
   ],
   "id": "282bc4560000617e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:24.878532Z",
     "start_time": "2025-06-29T20:33:24.024489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split into Train, Validation and Test sets\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "train_idx, test_idx = next(gss.split(df, groups=df[\"dyad_id\"]))\n",
    "test_df = df.iloc[test_idx]\n",
    "train_df = df.iloc[train_idx]\n",
    "\n",
    "train_idx, val_idx = next(gss.split(train_df, groups=train_df[\"dyad_id\"]))\n",
    "val_df = train_df.iloc[val_idx]\n",
    "train_df = train_df.iloc[train_idx]"
   ],
   "id": "51433a3f014528c2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:24.945003Z",
     "start_time": "2025-06-29T20:33:24.895279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df.loc[:, FEATURES] = train_df.loc[:, FEATURES].astype(\n",
    "  \"float32\",\n",
    "  copy=False\n",
    ")"
   ],
   "id": "a5ada7424fc6f996",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train",
   "id": "1053e63e8a6ccb76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define Fold and Epoch steps\n",
    "_For reusability_"
   ],
   "id": "78e3575a51038c9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:24.961666Z",
     "start_time": "2025-06-29T20:33:24.959874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create KFold object\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)"
   ],
   "id": "8eb0c16ea3f9a15d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:24.978504Z",
     "start_time": "2025-06-29T20:33:24.975878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define epoch step\n",
    "def epoch_step(model: nn.Module, optimizer: Optimizer, criterion: nn.Module,\n",
    "               scheduler: LRScheduler, train_loader: DataLoader, val_loader: DataLoader,\n",
    "               device: any) -> float:\n",
    "  model.train()\n",
    "  for X, y, di in train_loader:\n",
    "    X, y, di = map(lambda t: t.to(device, non_blocking=True), (X, y, di))\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(model(X, di), y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  model.eval()\n",
    "  val_losses = []\n",
    "  with (torch.no_grad()):\n",
    "    for X, y, di in val_loader:\n",
    "      X, y, di = map(lambda t: t.to(device, non_blocking=True), (X, y, di))\n",
    "      val_losses.append(criterion(model(X, di), y).item())\n",
    "\n",
    "  val_rmse = math.sqrt((sum(val_losses) / len(val_losses)))\n",
    "  scheduler.step(val_rmse)\n",
    "  return val_rmse"
   ],
   "id": "82612d122ae0a3ae",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:24.995959Z",
     "start_time": "2025-06-29T20:33:24.992310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define fold step\n",
    "def fold_step(fold: int, train_idx: List, val_idx: List,\n",
    "              dataset: Dataset, batch_size: int, num_epochs: int, patience: int,\n",
    "              model: nn.Module, device: any,\n",
    "              optimizer: Optimizer, criterion: nn.Module, scheduler: LRScheduler) -> (float, dict):\n",
    "  train_loader = DataLoader(\n",
    "    Subset(dataset, train_idx),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory=True\n",
    "  )\n",
    "\n",
    "  val_loader = DataLoader(\n",
    "    Subset(dataset, val_idx),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=10,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory=False\n",
    "  )\n",
    "\n",
    "  best_state = copy.deepcopy(model.state_dict())\n",
    "  best_rmse = float(\"inf\")\n",
    "  patience_left = patience\n",
    "\n",
    "  print(f\"Start epoch train for fold {fold}\")\n",
    "  for epoch in range(num_epochs):\n",
    "    val_rmse = epoch_step(model=model, optimizer=optimizer, criterion=criterion,\n",
    "                          scheduler=scheduler, train_loader=train_loader, val_loader=val_loader,\n",
    "                          device=device)\n",
    "    print(f\"Epoch {epoch + 1:02d}/{num_epochs}  |  val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "    if val_rmse < best_rmse - 1e-4:\n",
    "      best_rmse, patience_left = val_rmse, 10\n",
    "      best_state = model.state_dict()\n",
    "    else:\n",
    "      patience_left -= 1\n",
    "      if patience_left == 0:\n",
    "        print(\"Early stop.\")\n",
    "        break\n",
    "  model.load_state_dict(best_state)\n",
    "  model.eval()\n",
    "  preds, truth = [], []\n",
    "  with torch.no_grad():\n",
    "    for X, y, di in val_loader:\n",
    "      X, di = map(lambda t: t.to(device, non_blocking=True), (X, di))\n",
    "      preds.append(model(X, di).cpu())\n",
    "      truth.append(y)\n",
    "  preds = torch.cat(preds).numpy()\n",
    "  truth = torch.cat(truth).numpy()\n",
    "\n",
    "  rmse = np.sqrt(((preds - truth) ** 2).mean())\n",
    "  mae = np.abs(preds - truth).mean()\n",
    "  r2 = 1 - ((preds - truth) ** 2).sum() / ((truth - truth.mean()) ** 2).sum()\n",
    "  print(f\" Fold {fold}  RMSE {rmse:.4f} | MAE {mae:.4f} | R² {r2:.4f}\")\n",
    "\n",
    "  return rmse, copy.deepcopy(best_state)\n"
   ],
   "id": "959f98487abc0673",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Raw dataset",
   "id": "13f3e7e01662654"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split dataset",
   "id": "ff153528228b1350"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:25.238657Z",
     "start_time": "2025-06-29T20:33:25.009707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert df_scaled to pytorch Tensor\n",
    "dataset, dyad_to_idx = tuds.make_panel_datasets_dyad(\n",
    "  data=df,\n",
    "  features=FEATURES,\n",
    "  target=TARGET,\n",
    "  horizon=HORIZON,\n",
    ")"
   ],
   "id": "e38f7e2869374fc8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:25.268683Z",
     "start_time": "2025-06-29T20:33:25.266496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create DataLoaders for the 3 sets\n",
    "train_loader = DataLoader(\n",
    "  Subset(dataset, train_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=True,\n",
    "  num_workers=10,\n",
    "  persistent_workers=True,\n",
    "  prefetch_factor=2,\n",
    "  pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "  Subset(dataset, val_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False,\n",
    "  num_workers=10,\n",
    "  persistent_workers=True,\n",
    "  prefetch_factor=2,\n",
    "  pin_memory=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "  Subset(dataset, test_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False,\n",
    "  num_workers=10,\n",
    "  persistent_workers=True,\n",
    "  prefetch_factor=2,\n",
    "  pin_memory=False\n",
    ")"
   ],
   "id": "14dd8fdd80d8f0aa",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:25.294222Z",
     "start_time": "2025-06-29T20:33:25.271740Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"EXPORT_centered\"].describe()",
   "id": "2b924685051218fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.010187e+06\n",
       "mean     7.904368e-02\n",
       "std      1.075389e+00\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      0.000000e+00\n",
       "75%      1.100170e-03\n",
       "max      1.382330e+02\n",
       "Name: EXPORT_centered, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train model",
   "id": "d9e348e74bd91747"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:25.324280Z",
     "start_time": "2025-06-29T20:33:25.322318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save config\n",
    "SAVE_ENABLED = False\n",
    "SERIAL_NUMBER = f\"LSTM-{LEARNING_RATE}lr-{DROPOUT}d-{HIDDEN_SIZE}hs\"\n",
    "SERIAL_NUMBER = SERIAL_NUMBER.replace(\".\", \"_\")\n",
    "PATH_TO_FOLDER = \"../../models/\""
   ],
   "id": "1b837c71b6de51c1",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:33:25.352129Z",
     "start_time": "2025-06-29T20:33:25.350403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save best train iteration\n",
    "best_fold_state = None\n",
    "best_fold_rmse = float(\"inf\")"
   ],
   "id": "5e6e1bf43de12079",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:50:07.144460Z",
     "start_time": "2025-06-29T20:33:25.423936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(dataset))), 1):\n",
    "  model = tumod.DyadLSTM(\n",
    "    n_features=len(FEATURES),\n",
    "    n_layers=N_LAYERS,\n",
    "    n_dyads=len(dyad_to_idx),\n",
    "    embed_dim=EMBEDDING_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    dropout=DROPOUT,\n",
    "    horizon=HORIZON,\n",
    "  ).to(device=device)\n",
    "\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=PATIENCE\n",
    "  )\n",
    "\n",
    "  print(f\"=== FOLD {fold}/{N_SPLITS} ===\")\n",
    "  fold_rmse, best_state = fold_step(fold=fold,\n",
    "                                    train_idx=train_idx,\n",
    "                                    val_idx=val_idx,\n",
    "                                    dataset=dataset,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    num_epochs=NUM_EPOCHS,\n",
    "                                    patience=PATIENCE,\n",
    "                                    model=model,\n",
    "                                    device=device,\n",
    "                                    optimizer=optimizer,\n",
    "                                    criterion=criterion,\n",
    "                                    scheduler=scheduler)\n",
    "  if fold_rmse < best_fold_rmse:\n",
    "    best_fold_rmse = fold_rmse\n",
    "    best_fold_state = copy.deepcopy(best_state)"
   ],
   "id": "46a31ee0542aa6ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FOLD 1/5 ===\n",
      "Start epoch train for fold 1\n",
      "Epoch 01/25  |  val RMSE: 1.0327\n",
      "Epoch 02/25  |  val RMSE: 0.8673\n",
      "Epoch 03/25  |  val RMSE: 0.8566\n",
      "Epoch 04/25  |  val RMSE: 0.9117\n",
      "Epoch 05/25  |  val RMSE: 0.8973\n",
      "Epoch 06/25  |  val RMSE: 0.8721\n",
      "Epoch 07/25  |  val RMSE: 0.8894\n",
      "Epoch 08/25  |  val RMSE: 0.8709\n",
      "Epoch 09/25  |  val RMSE: 0.9324\n",
      "Epoch 10/25  |  val RMSE: 0.7329\n",
      "Epoch 11/25  |  val RMSE: 0.6861\n",
      "Epoch 12/25  |  val RMSE: 0.7189\n",
      "Epoch 13/25  |  val RMSE: 0.7214\n",
      "Epoch 14/25  |  val RMSE: 0.6324\n",
      "Epoch 15/25  |  val RMSE: 0.7807\n",
      "Epoch 16/25  |  val RMSE: 0.6690\n",
      "Epoch 17/25  |  val RMSE: 0.6706\n",
      "Epoch 18/25  |  val RMSE: 0.6661\n",
      "Epoch 19/25  |  val RMSE: 0.7029\n",
      "Epoch 20/25  |  val RMSE: 0.7826\n",
      "Epoch 21/25  |  val RMSE: 0.5689\n",
      "Epoch 22/25  |  val RMSE: 0.5686\n",
      "Epoch 23/25  |  val RMSE: 0.5906\n",
      "Epoch 24/25  |  val RMSE: 0.6133\n",
      "Epoch 25/25  |  val RMSE: 0.5376\n",
      " Fold 1  RMSE 0.5377 | MAE 0.0452 | R² 0.8009\n",
      "=== FOLD 2/5 ===\n",
      "Start epoch train for fold 2\n",
      "Epoch 01/25  |  val RMSE: 0.8338\n",
      "Epoch 02/25  |  val RMSE: 0.8210\n",
      "Epoch 03/25  |  val RMSE: 0.7095\n",
      "Epoch 04/25  |  val RMSE: 0.7174\n",
      "Epoch 05/25  |  val RMSE: 0.7328\n",
      "Epoch 06/25  |  val RMSE: 0.8289\n",
      "Epoch 07/25  |  val RMSE: 0.7933\n",
      "Epoch 08/25  |  val RMSE: 0.8634\n",
      "Epoch 09/25  |  val RMSE: 0.7697\n",
      "Epoch 10/25  |  val RMSE: 0.6461\n",
      "Epoch 11/25  |  val RMSE: 0.5717\n",
      "Epoch 12/25  |  val RMSE: 0.5946\n",
      "Epoch 13/25  |  val RMSE: 0.5663\n",
      "Epoch 14/25  |  val RMSE: 0.5834\n",
      "Epoch 15/25  |  val RMSE: 0.6215\n",
      "Epoch 16/25  |  val RMSE: 0.7317\n",
      "Epoch 17/25  |  val RMSE: 0.7069\n",
      "Epoch 18/25  |  val RMSE: 0.6032\n",
      "Epoch 19/25  |  val RMSE: 0.5863\n",
      "Epoch 20/25  |  val RMSE: 0.4607\n",
      "Epoch 21/25  |  val RMSE: 0.5056\n",
      "Epoch 22/25  |  val RMSE: 0.4955\n",
      "Epoch 23/25  |  val RMSE: 0.6034\n",
      "Epoch 24/25  |  val RMSE: 0.5442\n",
      "Epoch 25/25  |  val RMSE: 0.4898\n",
      " Fold 2  RMSE 0.4899 | MAE 0.0423 | R² 0.7855\n",
      "=== FOLD 3/5 ===\n",
      "Start epoch train for fold 3\n",
      "Epoch 01/25  |  val RMSE: 0.7507\n",
      "Epoch 02/25  |  val RMSE: 0.6845\n",
      "Epoch 03/25  |  val RMSE: 0.6649\n",
      "Epoch 04/25  |  val RMSE: 0.6869\n",
      "Epoch 05/25  |  val RMSE: 0.7198\n",
      "Epoch 06/25  |  val RMSE: 0.7597\n",
      "Epoch 07/25  |  val RMSE: 0.6536\n",
      "Epoch 08/25  |  val RMSE: 0.6872\n",
      "Epoch 09/25  |  val RMSE: 0.6835\n",
      "Epoch 10/25  |  val RMSE: 0.7137\n",
      "Epoch 11/25  |  val RMSE: 0.6427\n",
      "Epoch 12/25  |  val RMSE: 0.6484\n",
      "Epoch 13/25  |  val RMSE: 0.6666\n",
      "Epoch 14/25  |  val RMSE: 0.7119\n",
      "Epoch 15/25  |  val RMSE: 0.6671\n",
      "Epoch 16/25  |  val RMSE: 0.6499\n",
      "Epoch 17/25  |  val RMSE: 0.6940\n",
      "Epoch 18/25  |  val RMSE: 0.5633\n",
      "Epoch 19/25  |  val RMSE: 0.5281\n",
      "Epoch 20/25  |  val RMSE: 0.5138\n",
      "Epoch 21/25  |  val RMSE: 0.4896\n",
      "Epoch 22/25  |  val RMSE: 0.5679\n",
      "Epoch 23/25  |  val RMSE: 0.5470\n",
      "Epoch 24/25  |  val RMSE: 0.5188\n",
      "Epoch 25/25  |  val RMSE: 0.4698\n",
      " Fold 3  RMSE 0.4699 | MAE 0.0792 | R² 0.7491\n",
      "=== FOLD 4/5 ===\n",
      "Start epoch train for fold 4\n",
      "Epoch 01/25  |  val RMSE: 0.8794\n",
      "Epoch 02/25  |  val RMSE: 0.8674\n",
      "Epoch 03/25  |  val RMSE: 0.8150\n",
      "Epoch 04/25  |  val RMSE: 0.8707\n",
      "Epoch 05/25  |  val RMSE: 0.8472\n",
      "Epoch 06/25  |  val RMSE: 0.7552\n",
      "Epoch 07/25  |  val RMSE: 0.8493\n",
      "Epoch 08/25  |  val RMSE: 0.7890\n",
      "Epoch 09/25  |  val RMSE: 0.8133\n",
      "Epoch 10/25  |  val RMSE: 0.7881\n",
      "Epoch 11/25  |  val RMSE: 0.7694\n",
      "Epoch 12/25  |  val RMSE: 0.7696\n",
      "Epoch 13/25  |  val RMSE: 0.6320\n",
      "Epoch 14/25  |  val RMSE: 0.6397\n",
      "Epoch 15/25  |  val RMSE: 0.6439\n",
      "Epoch 16/25  |  val RMSE: 0.6276\n",
      "Epoch 17/25  |  val RMSE: 0.6415\n",
      "Epoch 18/25  |  val RMSE: 0.7294\n",
      "Epoch 19/25  |  val RMSE: 0.5676\n",
      "Epoch 20/25  |  val RMSE: 0.6788\n",
      "Epoch 21/25  |  val RMSE: 0.6428\n",
      "Epoch 22/25  |  val RMSE: 0.6642\n",
      "Epoch 23/25  |  val RMSE: 0.5644\n",
      "Epoch 24/25  |  val RMSE: 0.5967\n",
      "Epoch 25/25  |  val RMSE: 0.6870\n",
      " Fold 4  RMSE 0.6871 | MAE 0.0727 | R² 0.6138\n",
      "=== FOLD 5/5 ===\n",
      "Start epoch train for fold 5\n",
      "Epoch 01/25  |  val RMSE: 0.8236\n",
      "Epoch 02/25  |  val RMSE: 0.7446\n",
      "Epoch 03/25  |  val RMSE: 0.7524\n",
      "Epoch 04/25  |  val RMSE: 0.9472\n",
      "Epoch 05/25  |  val RMSE: 0.7658\n",
      "Epoch 06/25  |  val RMSE: 0.6891\n",
      "Epoch 07/25  |  val RMSE: 0.8080\n",
      "Epoch 08/25  |  val RMSE: 0.6753\n",
      "Epoch 09/25  |  val RMSE: 0.7861\n",
      "Epoch 10/25  |  val RMSE: 0.7225\n",
      "Epoch 11/25  |  val RMSE: 0.7142\n",
      "Epoch 12/25  |  val RMSE: 0.7068\n",
      "Epoch 13/25  |  val RMSE: 0.7341\n",
      "Epoch 14/25  |  val RMSE: 0.8055\n",
      "Epoch 15/25  |  val RMSE: 0.6565\n",
      "Epoch 16/25  |  val RMSE: 0.5634\n",
      "Epoch 17/25  |  val RMSE: 0.7336\n",
      "Epoch 18/25  |  val RMSE: 0.6263\n",
      "Epoch 19/25  |  val RMSE: 0.6265\n",
      "Epoch 20/25  |  val RMSE: 0.6958\n",
      "Epoch 21/25  |  val RMSE: 0.5569\n",
      "Epoch 22/25  |  val RMSE: 0.5460\n",
      "Epoch 23/25  |  val RMSE: 0.6400\n",
      "Epoch 24/25  |  val RMSE: 0.5383\n",
      "Epoch 25/25  |  val RMSE: 0.4936\n",
      " Fold 5  RMSE 0.4937 | MAE 0.0560 | R² 0.7802\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save Model",
   "id": "fdb87591cdaea243"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:50:12.689096Z",
     "start_time": "2025-06-29T21:50:12.663629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save({\n",
    "  \"model_state_dict\": best_fold_state,\n",
    "  \"model_hyperparams\": {\n",
    "    \"n_features\": len(FEATURES),\n",
    "    \"n_dyads\": len(dyad_to_idx),\n",
    "    \"embed_dim\": EMBEDDING_SIZE,\n",
    "    \"hidden_size\": HIDDEN_SIZE,\n",
    "    \"n_layers\": N_LAYERS,\n",
    "    \"dropout\": DROPOUT,\n",
    "    \"horizon\": HORIZON,\n",
    "  },\n",
    "  \"dyad_to_idx\": dyad_to_idx,\n",
    "  \"feature_names\": FEATURES,\n",
    "}, PATH_TO_FOLDER + SERIAL_NUMBER + \".pt\")"
   ],
   "id": "d0052a368e462d1d",
   "outputs": [],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
