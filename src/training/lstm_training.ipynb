{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BasicLSTM",
   "id": "a1d433415f0426aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation",
   "id": "e8067785cd8d7919"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import modules",
   "id": "1fe72819da94dd5d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-28T09:52:08.949001Z",
     "start_time": "2025-06-28T09:52:08.945480Z"
    }
   },
   "source": [
    "# Prediction using LSTM, GRU-LSTM, xLSTM\n",
    "import copy\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import KFold, GroupShuffleSplit\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "import thesis_utils.datastruc as tuds\n",
    "import thesis_utils.models as tumod"
   ],
   "outputs": [],
   "execution_count": 295
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Configuration",
   "id": "4284e3ddbaa79d6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:52:08.955982Z",
     "start_time": "2025-06-28T09:52:08.952357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Config for saving outputs\n",
    "SAVE_ENABLED = True\n",
    "SERIAL_NUMBER = \"NOT_SET\"\n",
    "\n",
    "# Model parameters\n",
    "HORIZON = 1\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 25\n",
    "HIDDEN_SIZE = 128\n",
    "N_LAYERS = 3\n",
    "DROPOUT = 0.2\n",
    "EMBEDDING_SIZE = 32\n",
    "\n",
    "# Train parameters\n",
    "TARGET = \"EXPORT_centered\"\n",
    "FEATURES = [\n",
    "  \"contig\", \"comlang_off\", \"colony\", \"smctry\",  # dist cepii categorical\n",
    "]\n",
    "N_SPLITS = 5\n",
    "PATIENCE = 5\n",
    "LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY = 0.01\n",
    "RANDOM_SEED = 16\n",
    "KEEP_FRAC = 1.0\n",
    "N_LAGS = 2\n",
    "SUBSAMPLE_ENABLED = True\n",
    "N_DYADS = 10\n",
    "\n",
    "EPS = 1e-19\n",
    "\n",
    "SANCTION_COLS = [\"arms\", \"military\", \"trade\", \"travel\", \"other\"]\n",
    "\n",
    "# Torch config\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = (\n",
    "  torch.device(\"cpu\")\n",
    ")"
   ],
   "id": "56e9b02ef240fd0a",
   "outputs": [],
   "execution_count": 296
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Data",
   "id": "c9e963c3ab4f2220"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:52:09.245926Z",
     "start_time": "2025-06-28T09:52:08.990439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processed = pd.read_parquet(path=\"../../data/model/processed.parquet\", engine=\"fastparquet\")\n",
    "df: DataFrame = processed.copy(deep=True)"
   ],
   "id": "9451e98a113f268d",
   "outputs": [],
   "execution_count": 297
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sort, shift and compute data",
   "id": "84523341884506e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:52:09.455762Z",
     "start_time": "2025-06-28T09:52:09.272128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sort data by Report + Partner + Year\n",
    "df[\"dyad_id\"] = df[\"ISO3_reporter\"] + \"_\" + df[\"ISO3_partner\"]\n",
    "df = df.sort_values(by=[\"dyad_id\", \"Year\"], ignore_index=True)"
   ],
   "id": "1dcefe0333d9c64b",
   "outputs": [],
   "execution_count": 298
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:52:09.572509Z",
     "start_time": "2025-06-28T09:52:09.507218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if SUBSAMPLE_ENABLED:\n",
    "  dyad_subsample = pd.Series(df[\"dyad_id\"].unique()).sample(n=N_DYADS, random_state=RANDOM_SEED, replace=False)\n",
    "  df = df[df[\"dyad_id\"].isin(dyad_subsample)]\n",
    "print(df[\"dyad_id\"].nunique())"
   ],
   "id": "37ec201db709a960",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "execution_count": 299
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:52:09.579554Z",
     "start_time": "2025-06-28T09:52:09.577460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[\"sanction\"] = (df[SANCTION_COLS]\n",
    "                  .sum(axis=1)).astype(int)"
   ],
   "id": "3fccd13d0f035fe6",
   "outputs": [],
   "execution_count": 300
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Coerce numerical values and convert dyad_id to categorical",
   "id": "7a9d823465c895"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:52:09.631959Z",
     "start_time": "2025-06-28T09:52:09.628519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_cols = [\"distw\", \"GDP_reporter\", \"GDP_partner\", \"sanction\", \"contig\",\n",
    "            \"comlang_off\", \"colony\", \"smctry\", \"Year\", ]\n",
    "df[num_cols] = df[num_cols].apply(pd.to_numeric, errors=\"coerce\").astype(float)\n",
    "df = df.dropna(subset=num_cols)"
   ],
   "id": "213988af4aee1df1",
   "outputs": [],
   "execution_count": 301
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:52:09.635539Z",
     "start_time": "2025-06-28T09:52:09.633661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "for col in [\"dyad_id\"]:\n",
    "  df[col] = pd.Categorical(df[col], categories=sorted(df[col].unique()))"
   ],
   "id": "c56872ce3b8a13d9",
   "outputs": [],
   "execution_count": 302
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Center data",
   "id": "d5984693829da5ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:52:09.662554Z",
     "start_time": "2025-06-28T09:52:09.660168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "center_columns = [\"distw\", \"GDP_reporter\", \"GDP_partner\", \"EXPORT\"]\n",
    "for col in center_columns:\n",
    "  col_max = df[col].max()\n",
    "  col_min = df[col].min()\n",
    "  df[col + \"_centered\"] = (df[col] - col_min) / (col_max - col_min) - 0.5\n",
    "\n",
    "FEATURES += [\"distw_centered\"]"
   ],
   "id": "aeb1d300d2098b4f",
   "outputs": [],
   "execution_count": 303
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:52:09.691356Z",
     "start_time": "2025-06-28T09:52:09.687979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lag_cols = [\"GDP_reporter_centered\", \"GDP_partner_centered\", \"sanction\"]\n",
    "for col in lag_cols:\n",
    "  for index in range(1, N_LAGS + 1):\n",
    "    df[f\"{col}_lag{index}\"] = df.groupby(\"dyad_id\", observed=True)[col].shift(index)"
   ],
   "id": "453b168d67f61597",
   "outputs": [],
   "execution_count": 304
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:52:09.719342Z",
     "start_time": "2025-06-28T09:52:09.716958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.dropna()\n",
    "FEATURES += [f\"{c}_lag{index}\" for c in lag_cols for index in range(1, N_LAGS + 1)]"
   ],
   "id": "b8a11cdcaed5f54b",
   "outputs": [],
   "execution_count": 305
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:52:09.747402Z",
     "start_time": "2025-06-28T09:52:09.745293Z"
    }
   },
   "cell_type": "code",
   "source": "FEATURES",
   "id": "ae986f5126d8781d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contig',\n",
       " 'comlang_off',\n",
       " 'colony',\n",
       " 'smctry',\n",
       " 'distw_centered',\n",
       " 'GDP_reporter_centered_lag1',\n",
       " 'GDP_reporter_centered_lag2',\n",
       " 'GDP_partner_centered_lag1',\n",
       " 'GDP_partner_centered_lag2',\n",
       " 'sanction_lag1',\n",
       " 'sanction_lag2']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 306
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split data",
   "id": "eab345a3bd4fc194"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:33:44.347288Z",
     "start_time": "2025-06-28T09:33:44.345128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embeddings\n",
    "dyad_to_idx = { dyad: i for i, dyad in enumerate(df[\"dyad_id\"].cat.categories) }\n",
    "df[\"dyad_idx\"] = df[\"dyad_id\"].map(dyad_to_idx).astype(int)"
   ],
   "id": "282bc4560000617e",
   "outputs": [],
   "execution_count": 237
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:33:44.396444Z",
     "start_time": "2025-06-28T09:33:44.392815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split into Train, Validation and Test sets\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "train_idx, test_idx = next(gss.split(df, groups=df[\"dyad_id\"]))\n",
    "test_df = df.iloc[test_idx]\n",
    "train_df = df.iloc[train_idx]\n",
    "\n",
    "train_idx, val_idx = next(gss.split(train_df, groups=train_df[\"dyad_id\"]))\n",
    "val_df = train_df.iloc[val_idx]\n",
    "train_df = train_df.iloc[train_idx]"
   ],
   "id": "51433a3f014528c2",
   "outputs": [],
   "execution_count": 238
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:33:44.427102Z",
     "start_time": "2025-06-28T09:33:44.424485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df.loc[:, FEATURES] = train_df.loc[:, FEATURES].astype(\n",
    "  \"float32\",\n",
    "  copy=False\n",
    ")"
   ],
   "id": "a5ada7424fc6f996",
   "outputs": [],
   "execution_count": 239
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train",
   "id": "1053e63e8a6ccb76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define Fold and Epoch steps\n",
    "_For reusability_"
   ],
   "id": "78e3575a51038c9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:33:44.489544Z",
     "start_time": "2025-06-28T09:33:44.488113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create KFold object\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)"
   ],
   "id": "8eb0c16ea3f9a15d",
   "outputs": [],
   "execution_count": 240
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:33:44.501417Z",
     "start_time": "2025-06-28T09:33:44.499038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define epoch step\n",
    "def epoch_step(model: nn.Module, optimizer: Optimizer, criterion: nn.Module,\n",
    "               scheduler: LRScheduler, train_loader: DataLoader, val_loader: DataLoader,\n",
    "               device: any) -> float:\n",
    "  model.train()\n",
    "  print(\"Training...\")\n",
    "  for X, y, di in train_loader:\n",
    "    X, y, di = map(lambda t: t.to(device, non_blocking=True), (X, y, di))\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(model(X, di), y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  print(\"Training done.\")\n",
    "\n",
    "  model.eval()\n",
    "  val_losses = []\n",
    "  with (torch.no_grad()):\n",
    "    for X, y, di in val_loader:\n",
    "      X, y, di = map(lambda t: t.to(device, non_blocking=True), (X, y, di))\n",
    "      val_losses.append(criterion(model(X, di), y).item())\n",
    "\n",
    "  val_rmse = math.sqrt((sum(val_losses) / len(val_losses)))\n",
    "  scheduler.step(val_rmse)\n",
    "  print(f\"Validation RMSE: {val_rmse:.4f} for epoch\")\n",
    "  return val_rmse"
   ],
   "id": "82612d122ae0a3ae",
   "outputs": [],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:33:44.552966Z",
     "start_time": "2025-06-28T09:33:44.549653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define fold step\n",
    "def fold_step(fold: int, train_idx: List, val_idx: List,\n",
    "              dataset: Dataset, batch_size: int, num_epochs: int, patience: int,\n",
    "              model: nn.Module, device: any,\n",
    "              optimizer: Optimizer, criterion: nn.Module, scheduler: LRScheduler) -> (float, dict):\n",
    "  train_loader = DataLoader(\n",
    "    Subset(dataset, train_idx),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory=True\n",
    "  )\n",
    "\n",
    "  val_loader = DataLoader(\n",
    "    Subset(dataset, val_idx),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=10,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory=False\n",
    "  )\n",
    "\n",
    "  best_state = copy.deepcopy(model.state_dict())\n",
    "  best_rmse = float(\"inf\")\n",
    "  patience_left = patience\n",
    "\n",
    "  print(f\"Start epoch train for fold {fold}\")\n",
    "  for epoch in range(num_epochs):\n",
    "    val_rmse = epoch_step(model=model, optimizer=optimizer, criterion=criterion,\n",
    "                          scheduler=scheduler, train_loader=train_loader, val_loader=val_loader,\n",
    "                          device=device)\n",
    "    print(f\"Epoch {epoch + 1:02d}/{num_epochs}  |  val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "    if val_rmse < best_rmse - 1e-4:\n",
    "      best_rmse, patience_left = val_rmse, 10\n",
    "      best_state = model.state_dict()\n",
    "    else:\n",
    "      patience_left -= 1\n",
    "      if patience_left == 0:\n",
    "        print(\"Early stop.\")\n",
    "        break\n",
    "  model.load_state_dict(best_state)\n",
    "  model.eval()\n",
    "  preds, truth = [], []\n",
    "  with torch.no_grad():\n",
    "    for X, y, di in val_loader:\n",
    "      X, di = map(lambda t: t.to(device, non_blocking=True), (X, di))\n",
    "      preds.append(model(X, di).cpu())\n",
    "      truth.append(y)\n",
    "  preds = torch.cat(preds).numpy()\n",
    "  truth = torch.cat(truth).numpy()\n",
    "\n",
    "  rmse = np.sqrt(((preds - truth) ** 2).mean())\n",
    "  mae = np.abs(preds - truth).mean()\n",
    "  r2 = 1 - ((preds - truth) ** 2).sum() / ((truth - truth.mean()) ** 2).sum()\n",
    "  print(f\" Fold {fold}  RMSE {rmse:.4f} | MAE {mae:.4f} | R² {r2:.4f}\")\n",
    "\n",
    "  return rmse, copy.deepcopy(best_state)\n"
   ],
   "id": "959f98487abc0673",
   "outputs": [],
   "execution_count": 242
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Raw dataset",
   "id": "13f3e7e01662654"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split dataset",
   "id": "ff153528228b1350"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:33:44.562503Z",
     "start_time": "2025-06-28T09:33:44.560309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert df_scaled to pytorch Tensor\n",
    "dataset, dyad_to_idx = tuds.make_panel_datasets_dyad(\n",
    "  data=df,\n",
    "  features=FEATURES,\n",
    "  target=TARGET,\n",
    "  horizon=HORIZON,\n",
    ")"
   ],
   "id": "e38f7e2869374fc8",
   "outputs": [],
   "execution_count": 243
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:33:44.611418Z",
     "start_time": "2025-06-28T09:33:44.609288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create DataLoaders for the 3 sets\n",
    "train_loader = DataLoader(\n",
    "  Subset(dataset, train_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=True,\n",
    "  num_workers=10,\n",
    "  persistent_workers=True,\n",
    "  prefetch_factor=2,\n",
    "  pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "  Subset(dataset, val_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False,\n",
    "  num_workers=10,\n",
    "  persistent_workers=True,\n",
    "  prefetch_factor=2,\n",
    "  pin_memory=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "  Subset(dataset, test_idx),\n",
    "  batch_size=BATCH_SIZE,\n",
    "  shuffle=False,\n",
    "  num_workers=10,\n",
    "  persistent_workers=True,\n",
    "  prefetch_factor=2,\n",
    "  pin_memory=False\n",
    ")"
   ],
   "id": "14dd8fdd80d8f0aa",
   "outputs": [],
   "execution_count": 244
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train model",
   "id": "d9e348e74bd91747"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:33:44.614261Z",
     "start_time": "2025-06-28T09:33:44.612916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save config\n",
    "SAVE_ENABLED = False\n",
    "SERIAL_NUMBER = f\"BasicLSTM-RawData\""
   ],
   "id": "1b837c71b6de51c1",
   "outputs": [],
   "execution_count": 245
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:33:44.640720Z",
     "start_time": "2025-06-28T09:33:44.638791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save best train iteration\n",
    "best_fold_state = None\n",
    "best_fold_rmse = float(\"inf\")"
   ],
   "id": "5e6e1bf43de12079",
   "outputs": [],
   "execution_count": 246
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T09:34:06.050548Z",
     "start_time": "2025-06-28T09:33:44.662046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(dataset))), 1):\n",
    "  model = tumod.DyadLSTM(\n",
    "    n_features=len(FEATURES),\n",
    "    n_layers=N_LAYERS,\n",
    "    n_dyads=len(dyad_to_idx),\n",
    "    embed_dim=32,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    dropout=DROPOUT,\n",
    "    horizon=HORIZON,\n",
    "  ).to(device=device)\n",
    "\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=PATIENCE\n",
    "  )\n",
    "\n",
    "  print(f\"=== FOLD {fold}/{N_SPLITS} ===\")\n",
    "  fold_rmse, best_state = fold_step(fold=fold,\n",
    "                                    train_idx=train_idx,\n",
    "                                    val_idx=val_idx,\n",
    "                                    dataset=dataset,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    num_epochs=NUM_EPOCHS,\n",
    "                                    patience=PATIENCE,\n",
    "                                    model=model,\n",
    "                                    device=device,\n",
    "                                    optimizer=optimizer,\n",
    "                                    criterion=criterion,\n",
    "                                    scheduler=scheduler)\n",
    "  if fold_rmse < best_fold_rmse:\n",
    "    best_fold_rmse = fold_rmse\n",
    "    best_fold_state = copy.deepcopy(best_state)"
   ],
   "id": "46a31ee0542aa6ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FOLD 1/5 ===\n",
      "Start epoch train for fold 1\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.2935 for epoch\n",
      "Epoch 01/25  |  val RMSE: 0.2935\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1683 for epoch\n",
      "Epoch 02/25  |  val RMSE: 0.1683\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1175 for epoch\n",
      "Epoch 03/25  |  val RMSE: 0.1175\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0743 for epoch\n",
      "Epoch 04/25  |  val RMSE: 0.0743\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0799 for epoch\n",
      "Epoch 05/25  |  val RMSE: 0.0799\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0754 for epoch\n",
      "Epoch 06/25  |  val RMSE: 0.0754\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0637 for epoch\n",
      "Epoch 07/25  |  val RMSE: 0.0637\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0417 for epoch\n",
      "Epoch 08/25  |  val RMSE: 0.0417\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0777 for epoch\n",
      "Epoch 09/25  |  val RMSE: 0.0777\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0843 for epoch\n",
      "Epoch 10/25  |  val RMSE: 0.0843\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0894 for epoch\n",
      "Epoch 11/25  |  val RMSE: 0.0894\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0945 for epoch\n",
      "Epoch 12/25  |  val RMSE: 0.0945\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0656 for epoch\n",
      "Epoch 13/25  |  val RMSE: 0.0656\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0401 for epoch\n",
      "Epoch 14/25  |  val RMSE: 0.0401\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0375 for epoch\n",
      "Epoch 15/25  |  val RMSE: 0.0375\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0641 for epoch\n",
      "Epoch 16/25  |  val RMSE: 0.0641\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0666 for epoch\n",
      "Epoch 17/25  |  val RMSE: 0.0666\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0586 for epoch\n",
      "Epoch 18/25  |  val RMSE: 0.0586\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0511 for epoch\n",
      "Epoch 19/25  |  val RMSE: 0.0511\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0367 for epoch\n",
      "Epoch 20/25  |  val RMSE: 0.0367\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0321 for epoch\n",
      "Epoch 21/25  |  val RMSE: 0.0321\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0376 for epoch\n",
      "Epoch 22/25  |  val RMSE: 0.0376\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0609 for epoch\n",
      "Epoch 23/25  |  val RMSE: 0.0609\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0741 for epoch\n",
      "Epoch 24/25  |  val RMSE: 0.0741\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0745 for epoch\n",
      "Epoch 25/25  |  val RMSE: 0.0745\n",
      " Fold 1  RMSE 0.0745 | MAE 0.0278 | R² -22.4635\n",
      "=== FOLD 2/5 ===\n",
      "Start epoch train for fold 2\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1880 for epoch\n",
      "Epoch 01/25  |  val RMSE: 0.1880\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1404 for epoch\n",
      "Epoch 02/25  |  val RMSE: 0.1404\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1082 for epoch\n",
      "Epoch 03/25  |  val RMSE: 0.1082\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1164 for epoch\n",
      "Epoch 04/25  |  val RMSE: 0.1164\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1014 for epoch\n",
      "Epoch 05/25  |  val RMSE: 0.1014\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0983 for epoch\n",
      "Epoch 06/25  |  val RMSE: 0.0983\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0989 for epoch\n",
      "Epoch 07/25  |  val RMSE: 0.0989\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0934 for epoch\n",
      "Epoch 08/25  |  val RMSE: 0.0934\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1036 for epoch\n",
      "Epoch 09/25  |  val RMSE: 0.1036\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0938 for epoch\n",
      "Epoch 10/25  |  val RMSE: 0.0938\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0946 for epoch\n",
      "Epoch 11/25  |  val RMSE: 0.0946\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0983 for epoch\n",
      "Epoch 12/25  |  val RMSE: 0.0983\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0961 for epoch\n",
      "Epoch 13/25  |  val RMSE: 0.0961\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0943 for epoch\n",
      "Epoch 14/25  |  val RMSE: 0.0943\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0916 for epoch\n",
      "Epoch 15/25  |  val RMSE: 0.0916\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0930 for epoch\n",
      "Epoch 16/25  |  val RMSE: 0.0930\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0940 for epoch\n",
      "Epoch 17/25  |  val RMSE: 0.0940\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0951 for epoch\n",
      "Epoch 18/25  |  val RMSE: 0.0951\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0946 for epoch\n",
      "Epoch 19/25  |  val RMSE: 0.0946\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0949 for epoch\n",
      "Epoch 20/25  |  val RMSE: 0.0949\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0953 for epoch\n",
      "Epoch 21/25  |  val RMSE: 0.0953\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0939 for epoch\n",
      "Epoch 22/25  |  val RMSE: 0.0939\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0920 for epoch\n",
      "Epoch 23/25  |  val RMSE: 0.0920\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0907 for epoch\n",
      "Epoch 24/25  |  val RMSE: 0.0907\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0901 for epoch\n",
      "Epoch 25/25  |  val RMSE: 0.0901\n",
      " Fold 2  RMSE 0.0901 | MAE 0.0349 | R² 0.4784\n",
      "=== FOLD 3/5 ===\n",
      "Start epoch train for fold 3\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1811 for epoch\n",
      "Epoch 01/25  |  val RMSE: 0.1811\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1068 for epoch\n",
      "Epoch 02/25  |  val RMSE: 0.1068\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0429 for epoch\n",
      "Epoch 03/25  |  val RMSE: 0.0429\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0658 for epoch\n",
      "Epoch 04/25  |  val RMSE: 0.0658\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0410 for epoch\n",
      "Epoch 05/25  |  val RMSE: 0.0410\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0631 for epoch\n",
      "Epoch 06/25  |  val RMSE: 0.0631\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0406 for epoch\n",
      "Epoch 07/25  |  val RMSE: 0.0406\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0341 for epoch\n",
      "Epoch 08/25  |  val RMSE: 0.0341\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0270 for epoch\n",
      "Epoch 09/25  |  val RMSE: 0.0270\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0419 for epoch\n",
      "Epoch 10/25  |  val RMSE: 0.0419\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0540 for epoch\n",
      "Epoch 11/25  |  val RMSE: 0.0540\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0309 for epoch\n",
      "Epoch 12/25  |  val RMSE: 0.0309\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0280 for epoch\n",
      "Epoch 13/25  |  val RMSE: 0.0280\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0291 for epoch\n",
      "Epoch 14/25  |  val RMSE: 0.0291\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0297 for epoch\n",
      "Epoch 15/25  |  val RMSE: 0.0297\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0265 for epoch\n",
      "Epoch 16/25  |  val RMSE: 0.0265\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0260 for epoch\n",
      "Epoch 17/25  |  val RMSE: 0.0260\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0292 for epoch\n",
      "Epoch 18/25  |  val RMSE: 0.0292\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0318 for epoch\n",
      "Epoch 19/25  |  val RMSE: 0.0318\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0318 for epoch\n",
      "Epoch 20/25  |  val RMSE: 0.0318\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0301 for epoch\n",
      "Epoch 21/25  |  val RMSE: 0.0301\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0276 for epoch\n",
      "Epoch 22/25  |  val RMSE: 0.0276\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0260 for epoch\n",
      "Epoch 23/25  |  val RMSE: 0.0260\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0253 for epoch\n",
      "Epoch 24/25  |  val RMSE: 0.0253\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0256 for epoch\n",
      "Epoch 25/25  |  val RMSE: 0.0256\n",
      " Fold 3  RMSE 0.0256 | MAE 0.0105 | R² 0.5559\n",
      "=== FOLD 4/5 ===\n",
      "Start epoch train for fold 4\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.3012 for epoch\n",
      "Epoch 01/25  |  val RMSE: 0.3012\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1956 for epoch\n",
      "Epoch 02/25  |  val RMSE: 0.1956\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1692 for epoch\n",
      "Epoch 03/25  |  val RMSE: 0.1692\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1463 for epoch\n",
      "Epoch 04/25  |  val RMSE: 0.1463\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1474 for epoch\n",
      "Epoch 05/25  |  val RMSE: 0.1474\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1278 for epoch\n",
      "Epoch 06/25  |  val RMSE: 0.1278\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1242 for epoch\n",
      "Epoch 07/25  |  val RMSE: 0.1242\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1214 for epoch\n",
      "Epoch 08/25  |  val RMSE: 0.1214\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1307 for epoch\n",
      "Epoch 09/25  |  val RMSE: 0.1307\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1507 for epoch\n",
      "Epoch 10/25  |  val RMSE: 0.1507\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1425 for epoch\n",
      "Epoch 11/25  |  val RMSE: 0.1425\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1234 for epoch\n",
      "Epoch 12/25  |  val RMSE: 0.1234\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1205 for epoch\n",
      "Epoch 13/25  |  val RMSE: 0.1205\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1196 for epoch\n",
      "Epoch 14/25  |  val RMSE: 0.1196\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1264 for epoch\n",
      "Epoch 15/25  |  val RMSE: 0.1264\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1217 for epoch\n",
      "Epoch 16/25  |  val RMSE: 0.1217\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1212 for epoch\n",
      "Epoch 17/25  |  val RMSE: 0.1212\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1258 for epoch\n",
      "Epoch 18/25  |  val RMSE: 0.1258\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1303 for epoch\n",
      "Epoch 19/25  |  val RMSE: 0.1303\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1316 for epoch\n",
      "Epoch 20/25  |  val RMSE: 0.1316\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1305 for epoch\n",
      "Epoch 21/25  |  val RMSE: 0.1305\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1282 for epoch\n",
      "Epoch 22/25  |  val RMSE: 0.1282\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1260 for epoch\n",
      "Epoch 23/25  |  val RMSE: 0.1260\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1240 for epoch\n",
      "Epoch 24/25  |  val RMSE: 0.1240\n",
      "Early stop.\n",
      " Fold 4  RMSE 0.1240 | MAE 0.0368 | R² 0.3937\n",
      "=== FOLD 5/5 ===\n",
      "Start epoch train for fold 5\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.2061 for epoch\n",
      "Epoch 01/25  |  val RMSE: 0.2061\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.1183 for epoch\n",
      "Epoch 02/25  |  val RMSE: 0.1183\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0721 for epoch\n",
      "Epoch 03/25  |  val RMSE: 0.0721\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0865 for epoch\n",
      "Epoch 04/25  |  val RMSE: 0.0865\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0810 for epoch\n",
      "Epoch 05/25  |  val RMSE: 0.0810\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0803 for epoch\n",
      "Epoch 06/25  |  val RMSE: 0.0803\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0831 for epoch\n",
      "Epoch 07/25  |  val RMSE: 0.0831\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0788 for epoch\n",
      "Epoch 08/25  |  val RMSE: 0.0788\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0681 for epoch\n",
      "Epoch 09/25  |  val RMSE: 0.0681\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0642 for epoch\n",
      "Epoch 10/25  |  val RMSE: 0.0642\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0637 for epoch\n",
      "Epoch 11/25  |  val RMSE: 0.0637\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0657 for epoch\n",
      "Epoch 12/25  |  val RMSE: 0.0657\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0692 for epoch\n",
      "Epoch 13/25  |  val RMSE: 0.0692\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0672 for epoch\n",
      "Epoch 14/25  |  val RMSE: 0.0672\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0708 for epoch\n",
      "Epoch 15/25  |  val RMSE: 0.0708\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0695 for epoch\n",
      "Epoch 16/25  |  val RMSE: 0.0695\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0667 for epoch\n",
      "Epoch 17/25  |  val RMSE: 0.0667\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0636 for epoch\n",
      "Epoch 18/25  |  val RMSE: 0.0636\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0631 for epoch\n",
      "Epoch 19/25  |  val RMSE: 0.0631\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0650 for epoch\n",
      "Epoch 20/25  |  val RMSE: 0.0650\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0625 for epoch\n",
      "Epoch 21/25  |  val RMSE: 0.0625\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0654 for epoch\n",
      "Epoch 22/25  |  val RMSE: 0.0654\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0697 for epoch\n",
      "Epoch 23/25  |  val RMSE: 0.0697\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0675 for epoch\n",
      "Epoch 24/25  |  val RMSE: 0.0675\n",
      "Training...\n",
      "Training done.\n",
      "Validation RMSE: 0.0624 for epoch\n",
      "Epoch 25/25  |  val RMSE: 0.0624\n",
      " Fold 5  RMSE 0.0624 | MAE 0.0209 | R² 0.6121\n"
     ]
    }
   ],
   "execution_count": 247
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Lagged features 🐌",
   "id": "16acca6c1bd49c45"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
